{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data visualization\n",
        "\n",
        "## Usefull links\n",
        "\n",
        "- [Matplotlib](https://matplotlib.org/)\n",
        "- [Seaborn](https://seaborn.pydata.org/)\n",
        "- [Plotly](https://plot.ly/python/)\n",
        "- [Bokeh](https://bokeh.pydata.org/en/latest/)\n",
        "- [Altair](https://altair-viz.github.io/)\n",
        "- [Pygal](http://www.pygal.org/en/stable/)\n",
        "- [Plotnine](https://plotnine.readthedocs.io/en/stable/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "\n",
        "from pyramidal.pytorch.Generators.DataModule import DataModule\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datavariant = 'baseline'\n",
        "\n",
        "# transform = lambda x: x.permute(3, 2, 0, 1)\n",
        "dm = DataModule(\n",
        "  datavariant,\n",
        "  batch_size=9,\n",
        "  normalize_head='none',\n",
        "  normalize_tail='none',\n",
        "  # custom_transform_head=transform,\n",
        "  # custom_transform_tail=transform\n",
        "  is_half=False,\n",
        ")\n",
        "\n",
        "dm.setup('test')\n",
        "gen_batch = dm.datamodule_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gen_batch[0]\n",
        "# gen_batch[0]\n",
        "# gen_batch[1]\n",
        "# gen_batch[2]\n",
        "# ...\n",
        "x, y, path = gen_batch[0]\n",
        "x_np = x.detach().cpu().numpy()\n",
        "y_np = y.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference with models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyramidal.pytorch.inference import load_model_from_mlflow\n",
        "\n",
        "model = load_model_from_mlflow(\n",
        "  datavariant='baseline',\n",
        "  what_choice='best'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x, y, path = gen_batch[0]\n",
        "y_hat = model(x)\n",
        "x = x.detach().cpu().numpy()\n",
        "y = y.detach().cpu().numpy()\n",
        "y_hat = y_hat.detach().cpu().numpy()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('pyramidal')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f22e135b9bb4e9e8992e97da8079381f50a82991bc5ab04d325a03975681dceb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
